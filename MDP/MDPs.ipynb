{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "MDP Project edited by Marjan choodari milani\n",
    "***\n",
    "Master student in Artificial intelligence\n",
    "***\n",
    "2021 Summer\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self,height,width,start,goal):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "\n",
    "        self.R = np.zeros((height,width)) -1\n",
    "\n",
    "        self.R[2,:-1] = np.nan\n",
    "\n",
    "        self.goal = goal\n",
    "        self.R[self.goal] = 20\n",
    "        \n",
    "        self.S = []       \n",
    "        for index, reward in np.ndenumerate(self.R):\n",
    "\n",
    "            if(not np.isnan(reward)):\n",
    "                self.S.append(index)\n",
    "        self.S = np.asarray(self.S)\n",
    "\n",
    "\n",
    "        self.A = ['u','d','l','r']\n",
    "        \n",
    "\n",
    "        self.s = list(start)\n",
    "        \n",
    " \n",
    "        self.G_t = 0\n",
    "        \n",
    "        self.is_done = False\n",
    "        \n",
    "\n",
    "        self.v = np.empty((self.height,self.width))\n",
    "        self.v[:,:] = np.nan\n",
    "        \n",
    "    def get_rewards(self):\n",
    "        return self.G_t\n",
    "    \n",
    "    def get_possible_rewards(self):\n",
    "        return self.R\n",
    "    \n",
    "    def get_possible_states(self):\n",
    "        return self.S\n",
    "    \n",
    "    def get_state(self):\n",
    "        return self.s\n",
    "    \n",
    "    def get_actions(self):\n",
    "        return self.A\n",
    "    \n",
    "    def get_grid_world(self):\n",
    "        grid_world = np.chararray((self.width, self.height),unicode=True)\n",
    "        grid_world[:] = '-'\n",
    "        grid_world[self.s[0],self.s[1]]= 'a'\n",
    "        grid_world[2,:-1] = 'o'\n",
    "        grid_world[self.goal] = 'g'\n",
    "        return grid_world\n",
    "     \n",
    "    def step(self, action,print_info):\n",
    "        new_s,new_r = self.take_step(self.s,action)\n",
    "        self.s = new_s\n",
    "        if(print_info):\n",
    "            print(f'old_s:{self.s} new_s:{new_s} r_t:{new_r} G_t:{self.G_t}')\n",
    "            print(f\"World \\n {self.get_grid_world()}\")\n",
    "        \n",
    "        self.is_done = (self.s[0] == self.goal[0] and self.s[1] == self.goal[1])\n",
    "            \n",
    "        return new_r,new_s,self.is_done\n",
    "        \n",
    "    def check_if_s_in_S(self,s):\n",
    "        for possible_s in self.S:\n",
    "            if(possible_s[0] == s[0] and possible_s[1] == s[1]):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def is_out_of_bounds(self,new_s):\n",
    "        if((new_s[0] < 0 or new_s[0]>self.height-1) or (new_s[1] < 0 or new_s[1]>self.width-1)):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def take_step(self,s,a):\n",
    "        if(a not in self.A):\n",
    "            raise ValueError('Unknown action', a)\n",
    "        new_s = s.copy()\n",
    "        if(a == 'u'):\n",
    "            new_s[0] -= 1\n",
    "        if(a == 'd'):\n",
    "            new_s[0] += 1\n",
    "        if(a == 'l'):\n",
    "            new_s[1] -= 1\n",
    "        if(a == 'r'):\n",
    "            new_s[1] += 1\n",
    "         \n",
    "\n",
    "        if(self.is_out_of_bounds(new_s)):\n",
    "            return s,-1\n",
    "\n",
    "        elif(not self.check_if_s_in_S(new_s)):\n",
    "            return s,-1\n",
    "        return new_s,self.R[new_s[0],new_s[1]]\n",
    "    \n",
    "    def get_v(self,immediate_r,future_r):\n",
    "        return immediate_r + future_r\n",
    "    \n",
    "    def update_coords_value(self,point,successor):\n",
    "        if(not self.is_out_of_bounds(point)):\n",
    "            self.v[point] = self.get_v(self.R[point],self.R[successor])\n",
    "            return point\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def get_r(self,prev_s,new_s):\n",
    "        if(not self.is_out_of_bounds(new_s)):\n",
    "            if(np.isnan(self.prev_v[new_s[0],new_s[1]])):\n",
    "                return None\n",
    "            if(not np.isnan(self.prev_v[new_s[0],new_s[1]])):\n",
    "                new_r= self.prev_v[new_s[0],new_s[1]]\n",
    "            else:\n",
    "                new_r =  self.R[new_s[0],new_s[1]]\n",
    "            \n",
    "            if(np.isnan(self.prev_v[prev_s[0],prev_s[1]])):\n",
    "                return new_r\n",
    "            if(new_r > self.prev_v[prev_s[0],prev_s[1]]):\n",
    "                return_r= new_r\n",
    "            else:\n",
    "                return_r= self.prev_v[prev_s[0],prev_s[1]]\n",
    "            return return_r\n",
    "                \n",
    "        return None\n",
    "    \n",
    "    def max_r_best_a(self,s):\n",
    "        if(not np.isnan(self.prev_v[s[0],s[1]])):\n",
    "            return None\n",
    "        \n",
    "        above_p = (s[0]-1,s[1])\n",
    "        below_p = (s[0]+1,s[1])\n",
    "        left_p  = (s[0],s[1]-1)\n",
    "        right_p = (s[0],s[1]+1)\n",
    "        \n",
    "        above_p_r= self.get_r(s,above_p)\n",
    "        below_p_r = self.get_r(s,below_p)\n",
    "        left_p_r = self.get_r(s,left_p)\n",
    "        right_p_r = self.get_r(s,right_p)\n",
    "         \n",
    "        best_r = -1000\n",
    "        if(above_p_r is not None and  (above_p_r>best_r)):\n",
    "            best_r = above_p_r\n",
    "        if(below_p_r is not None and  (below_p_r>best_r)):\n",
    "            best_r = below_p_r\n",
    "        if(left_p_r is not None and (left_p_r>best_r)):\n",
    "            best_r = left_p_r\n",
    "        if(right_p_r is not None and (right_p_r>best_r)):\n",
    "            best_r = right_p_r\n",
    "        if(best_r == -1000):\n",
    "            return np.nan\n",
    "        \n",
    "        return best_r\n",
    "    \n",
    "    def is_obstacle(self,s):\n",
    "        if(np.isnan(self.R[s[0],s[1]])):\n",
    "            return True\n",
    "        \n",
    "    def get_value_iterative(self,point):\n",
    "        if(point is None or self.is_out_of_bounds(point)):\n",
    "            return\n",
    "        eps = 1e-20\n",
    "        max_iterations = 100\n",
    "        self.v[point] = self.get_v(self.R[point[0],point[1]],0)\n",
    "        for i in range(max_iterations):\n",
    "            self.prev_v = np.copy(self.v)\n",
    "            for s in self.S:\n",
    "                max_r = self.max_r_best_a(s)\n",
    "                if(max_r is not None):\n",
    "                    self.v[s[0],s[1]] = self.get_v(self.R[s[0],s[1]],max_r)\n",
    "                    \n",
    "            if (np.sum(np.fabs(self.prev_v - self.v)) <= eps):\n",
    "                print ('Value-iteration converged at iteration# %d.' %(i+1))\n",
    "                break\n",
    "        \n",
    "        return self.v\n",
    "    \n",
    "    def get_value_function(self):\n",
    "        return self.get_value_iterative(self.goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World \n",
      " [['g' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['o' 'o' 'o' 'o' 'o' 'o' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['a' '-' '-' '-' '-' '-' '-']]\n"
     ]
    }
   ],
   "source": [
    "height=7\n",
    "width=7\n",
    "\n",
    "env = Environment(height=7,width=7,start=(height-1,0),goal=(0,0))\n",
    "print(f\"World \\n {env.get_grid_world()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class RandomAgent():\n",
    "    def __init__(self, actions):\n",
    "        self.actions = actions\n",
    "        self.num_actions = len(actions)\n",
    "        \n",
    "        self.r_t = np.array([])\n",
    "  \n",
    "    def step(self,s=None):\n",
    "        return self.actions[random.randint(0, self.num_actions-1)]\n",
    "    \n",
    "    def update(self,new_s,reward):\n",
    "        self.s = new_s\n",
    "        self.r_t = np.append(self.r_t,reward)\n",
    "        self.G_t += reward\n",
    "        return self.r_t,self.G_t\n",
    "    \n",
    "class GreedyAgent():\n",
    "    def __init__(self, actions,value_func,height=7,width=7):\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        \n",
    "        self.actions = actions\n",
    "        self.num_actions = len(actions)\n",
    "        self.value_func = value_func\n",
    "        \n",
    "        self.r_t = np.array([])\n",
    "\n",
    "        self.G_t = 0\n",
    "    \n",
    "    def is_out_of_bounds(self,new_s):\n",
    "        if((new_s[0] < 0 or new_s[0]>self.height-1) or (new_s[1] < 0 or new_s[1]>self.width-1)):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def get_value(self,possible_s):\n",
    "        if(not self.is_out_of_bounds(possible_s)):\n",
    "            return self.value_func[possible_s[0],possible_s[1]]\n",
    "        return None\n",
    "    \n",
    "    def step(self,s):\n",
    "        above_p = (s[0]-1,s[1])\n",
    "        below_p = (s[0]+1,s[1])\n",
    "        left_p  = (s[0],s[1]-1)\n",
    "        right_p = (s[0],s[1]+1)\n",
    "        \n",
    "        above_p_v= self.get_value(above_p)\n",
    "        below_p_v = self.get_value(below_p)\n",
    "        left_p_v = self.get_value(left_p)\n",
    "        right_p_v = self.get_value(right_p)\n",
    "        \n",
    "\n",
    "        best_a = [False] *4\n",
    "    \n",
    "        best_v = -1000\n",
    "        if(above_p_v is not None and  (above_p_v>best_v)):\n",
    "            best_v = above_p_v\n",
    "            best_a[0] = True\n",
    "        if(below_p_v is not None and  (below_p_v>best_v)):\n",
    "            best_v = below_p_v\n",
    "            best_a = [False] *4\n",
    "            best_a[1] = True\n",
    "        if(left_p_v is not None and (left_p_v>best_v)):\n",
    "            best_v = left_p_v\n",
    "            best_a = [False] *4\n",
    "            best_a[2] = True\n",
    "        if(right_p_v is not None and (right_p_v>best_v)):\n",
    "            best_v = right_p_v\n",
    "            best_a = [False] *4\n",
    "            best_a[3] = True\n",
    "    \n",
    "        return self.actions[np.where(best_a)[0][0]]\n",
    "\n",
    "    def update(self,new_s,reward):\n",
    "        self.s = new_s\n",
    "        self.r_t = np.append(self.r_t,reward)\n",
    "        self.G_t += reward\n",
    "        return self.r_t,self.G_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment():\n",
    "    def __init__(self,env,agent):\n",
    "        self.env = env\n",
    "        self.agent = agent\n",
    "        \n",
    "    def run(self, num_steps,print_info=False):\n",
    "        steps = 0\n",
    "        done = False\n",
    "        reward = .0\n",
    "        rewards = np.array([])\n",
    "        losses = []\n",
    "\n",
    "        while steps < num_steps:       \n",
    "            action = self.agent.step(env.get_state())\n",
    "            reward,new_s,is_done = self.env.step(action,print_info=print_info)\n",
    "            r_t, cumulative_r = self.agent.update(new_s,reward)\n",
    "            if(print_info):\n",
    "                print(f\"*** Step: {steps} ***\")\n",
    "                print(f\"Cumulative_r:{cumulative_r}\")\n",
    "            steps += 1\n",
    "            \n",
    "            if(is_done):\n",
    "                if(print_info):\n",
    "                    print(f\"At Goal:{new_s}\")\n",
    "                break\n",
    "            \n",
    "        return cumulative_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Function \n",
      " [[20. 19. 18. 17. 16. 15. 14.]\n",
      " [19. 18. 17. 16. 15. 14. 13.]\n",
      " [nan nan nan nan nan nan 12.]\n",
      " [ 5.  6.  7.  8.  9. 10. 11.]\n",
      " [ 4.  5.  6.  7.  8.  9. 10.]\n",
      " [ 3.  4.  5.  6.  7.  8.  9.]\n",
      " [ 2.  3.  4.  5.  6.  7.  8.]]\n"
     ]
    }
   ],
   "source": [
    "height=7\n",
    "width=7\n",
    "\n",
    "env = Environment(height=7,width=7,start=(height-1,0),goal=(0,0))\n",
    "print(f\"Value Function \\n {env.get_value_function()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-dbde251ce354>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m  \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import  pandas as pd\n",
    "\n",
    "greedy_agent_cum_r = []\n",
    "random_agent_cum_r = []\n",
    "eight=7\n",
    "width=7\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "for i in range(20):\n",
    "    env = Environment(height=7,width=7,start=(height-1,0),goal=(0,0))\n",
    "    random_agent = RandomAgent(env.get_actions())\n",
    "    exp = Experiment(agent=random_agent,env=env)\n",
    "    random_agent_cum_r.append(exp.run(50,False))\n",
    "    \n",
    "for i in range(20):\n",
    "    env = Environment(height=7,width=7,start=(height-1,0),goal=(0,0))\n",
    "    greedy_agent = GreedyAgent(env.get_actions(),env.get_value_function())\n",
    "    exp = Experiment(agent=greedy_agent,env=env)\n",
    "    greedy_agent_cum_r.append(exp.run(50,False))\n",
    "\n",
    "def mean(lst): \n",
    "    return sum(lst) / len(lst) \n",
    "\n",
    "def autolabel(rects, xpos='center'):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar in *rects*, displaying its height.\n",
    "\n",
    "    *xpos* indicates which side to place the text w.r.t. the center of\n",
    "    the bar. It can be one of the following {'center', 'right', 'left'}.\n",
    "    \"\"\"\n",
    "\n",
    "    ha = {'center': 'center', 'right': 'left', 'left': 'right'}\n",
    "    offset = {'center': 0, 'right': 1, 'left': -1}\n",
    "\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(offset[xpos]*3, 3),  # use 3 points offset\n",
    "                    textcoords=\"offset points\",  # in both directions\n",
    "                    ha=ha[xpos], va='bottom')\n",
    "        break\n",
    "        \n",
    "    \n",
    "greedy_agent_mean_r = mean(greedy_agent_cum_r)\n",
    "random_agent_mean_r = mean(random_agent_cum_r)\n",
    "\n",
    "df = pd.DataFrame({'alg':['Greedy', 'Random'], 'cumulative_reward':[greedy_agent_mean_r, random_agent_mean_r]})\n",
    "ax = df.plot.bar(x='alg', y='cumulative_reward', rot=0)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.250, p.get_height() * 1.005))\n",
    "    \n",
    "plt.ylabel('Average Cumulative Return over 20 runs')\n",
    "plt.title('Average Cumulative Return for Random and Greedy Agents')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old_s:[6, 0] new_s:[6, 0] r_t:-1 G_t:0\n",
      "World \n",
      " [['g' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['o' 'o' 'o' 'o' 'o' 'o' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['a' '-' '-' '-' '-' '-' '-']]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RandomAgent' object has no attribute 'G_t'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c1e01097d40d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrandom_agent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mexp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_agent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprint_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-0474fdca5753>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, num_steps, print_info)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew_s\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mis_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprint_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprint_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mr_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcumulative_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_s\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprint_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"*** Step: {steps} ***\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-e72fb9021286>\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, new_s, reward)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_s\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG_t\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG_t\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomAgent' object has no attribute 'G_t'"
     ]
    }
   ],
   "source": [
    "height=7\n",
    "width=7\n",
    "\n",
    "env = Environment(height=7,width=7,start=(height-1,0),goal=(0,0))\n",
    "random_agent = RandomAgent(env.get_actions())\n",
    "exp = Experiment(agent=random_agent,env=env)\n",
    "exp.run(50,print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old_s:[5, 0] new_s:[5, 0] r_t:-1.0 G_t:0\n",
      "World \n",
      " [['g' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['o' 'o' 'o' 'o' 'o' 'o' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['a' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']]\n",
      "*** Step: 0 ***\n",
      "Cumulative_r:-1.0\n",
      "old_s:[4, 0] new_s:[4, 0] r_t:-1.0 G_t:0\n",
      "World \n",
      " [['g' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['o' 'o' 'o' 'o' 'o' 'o' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['a' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']]\n",
      "*** Step: 1 ***\n",
      "Cumulative_r:-2.0\n",
      "old_s:[3, 0] new_s:[3, 0] r_t:-1.0 G_t:0\n",
      "World \n",
      " [['g' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['o' 'o' 'o' 'o' 'o' 'o' '-']\n",
      " ['a' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']]\n",
      "*** Step: 2 ***\n",
      "Cumulative_r:-3.0\n",
      "old_s:[3, 1] new_s:[3, 1] r_t:-1.0 G_t:0\n",
      "World \n",
      " [['g' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['o' 'o' 'o' 'o' 'o' 'o' '-']\n",
      " ['-' 'a' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']]\n",
      "*** Step: 3 ***\n",
      "Cumulative_r:-4.0\n",
      "old_s:[3, 2] new_s:[3, 2] r_t:-1.0 G_t:0\n",
      "World \n",
      " [['g' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['o' 'o' 'o' 'o' 'o' 'o' '-']\n",
      " ['-' '-' 'a' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']]\n",
      "*** Step: 4 ***\n",
      "Cumulative_r:-5.0\n",
      "old_s:[3, 3] new_s:[3, 3] r_t:-1.0 G_t:0\n",
      "World \n",
      " [['g' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['o' 'o' 'o' 'o' 'o' 'o' '-']\n",
      " ['-' '-' '-' 'a' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']]\n",
      "*** Step: 5 ***\n",
      "Cumulative_r:-6.0\n",
      "old_s:[3, 4] new_s:[3, 4] r_t:-1.0 G_t:0\n",
      "World \n",
      " [['g' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['o' 'o' 'o' 'o' 'o' 'o' '-']\n",
      " ['-' '-' '-' '-' 'a' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']]\n",
      "*** Step: 6 ***\n",
      "Cumulative_r:-7.0\n",
      "old_s:[3, 5] new_s:[3, 5] r_t:-1.0 G_t:0\n",
      "World \n",
      " [['g' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['o' 'o' 'o' 'o' 'o' 'o' '-']\n",
      " ['-' '-' '-' '-' '-' 'a' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']]\n",
      "*** Step: 7 ***\n",
      "Cumulative_r:-8.0\n",
      "old_s:[3, 6] new_s:[3, 6] r_t:-1.0 G_t:0\n",
      "World \n",
      " [['g' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['o' 'o' 'o' 'o' 'o' 'o' '-']\n",
      " ['-' '-' '-' '-' '-' '-' 'a']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']]\n",
      "*** Step: 8 ***\n",
      "Cumulative_r:-9.0\n",
      "old_s:[2, 6] new_s:[2, 6] r_t:-1.0 G_t:0\n",
      "World \n",
      " [['g' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['o' 'o' 'o' 'o' 'o' 'o' 'a']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']]\n",
      "*** Step: 9 ***\n",
      "Cumulative_r:-10.0\n",
      "old_s:[1, 6] new_s:[1, 6] r_t:-1.0 G_t:0\n",
      "World \n",
      " [['g' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' 'a']\n",
      " ['o' 'o' 'o' 'o' 'o' 'o' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']]\n",
      "*** Step: 10 ***\n",
      "Cumulative_r:-11.0\n",
      "old_s:[0, 6] new_s:[0, 6] r_t:-1.0 G_t:0\n",
      "World \n",
      " [['g' '-' '-' '-' '-' '-' 'a']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['o' 'o' 'o' 'o' 'o' 'o' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']]\n",
      "*** Step: 11 ***\n",
      "Cumulative_r:-12.0\n",
      "old_s:[0, 5] new_s:[0, 5] r_t:-1.0 G_t:0\n",
      "World \n",
      " [['g' '-' '-' '-' '-' 'a' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['o' 'o' 'o' 'o' 'o' 'o' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']]\n",
      "*** Step: 12 ***\n",
      "Cumulative_r:-13.0\n",
      "old_s:[0, 4] new_s:[0, 4] r_t:-1.0 G_t:0\n",
      "World \n",
      " [['g' '-' '-' '-' 'a' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['o' 'o' 'o' 'o' 'o' 'o' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']]\n",
      "*** Step: 13 ***\n",
      "Cumulative_r:-14.0\n",
      "old_s:[0, 3] new_s:[0, 3] r_t:-1.0 G_t:0\n",
      "World \n",
      " [['g' '-' '-' 'a' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['o' 'o' 'o' 'o' 'o' 'o' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']]\n",
      "*** Step: 14 ***\n",
      "Cumulative_r:-15.0\n",
      "old_s:[0, 2] new_s:[0, 2] r_t:-1.0 G_t:0\n",
      "World \n",
      " [['g' '-' 'a' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['o' 'o' 'o' 'o' 'o' 'o' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']]\n",
      "*** Step: 15 ***\n",
      "Cumulative_r:-16.0\n",
      "old_s:[0, 1] new_s:[0, 1] r_t:-1.0 G_t:0\n",
      "World \n",
      " [['g' 'a' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['o' 'o' 'o' 'o' 'o' 'o' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']]\n",
      "*** Step: 16 ***\n",
      "Cumulative_r:-17.0\n",
      "old_s:[0, 0] new_s:[0, 0] r_t:20.0 G_t:0\n",
      "World \n",
      " [['g' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['o' 'o' 'o' 'o' 'o' 'o' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-' '-' '-']]\n",
      "*** Step: 17 ***\n",
      "Cumulative_r:3.0\n",
      "At Goal:[0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height=7\n",
    "width=7\n",
    "\n",
    "env = Environment(height=7,width=7,start=(height-1,0),goal=(0,0))\n",
    "random_agent = GreedyAgent(env.get_actions(),env.get_value_function())\n",
    "exp = Experiment(agent=random_agent,env=env)\n",
    "exp.run(50,True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
